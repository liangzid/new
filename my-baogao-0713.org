#+title:上一周的实验情况
#+latex_class: elegantpaper

上一周按照王老师的要求重新进行了实验的验证，这次是一点点从微小的地方开始的验证。下面是进行的实验：

| 验证对象               | 验证方法                                                                     | 验证结论    |
| 基于神经网络的匹配函数 | 单独对基于神经网络的匹配函数进行匹配的精度测试，并将之与传统的相似度进行比较 | 正常        |
| search on graph模块    | 人为设计了一些节点，之后将inner product，l2，cosine等度量进行了测试          | 正常        |
| hnsw+NN                | 使用MLP作为度量函数进行实验，在数据集上进行实验                              | 召回率接近0 |
| NN+遍历搜索            | 同上                                                                         | 召回率接近0 |
|                        |                                                                              |             |

结论：问题出在数据集上。如果将数据集中所有的item看作是被搜索的节点，然后使用这些item进行graph的构建，那么当输入一个user时，并不一定可以找到与之对应的item.(概率很低.)
我在60400个item上进行了实验,发现无论是训练好的神经网络还是传统相似度都很难对特定的user输入找到特定的item. 因此,排查完模型没有问题之后, 我将注意力集中在数据集上.

数据集的格式是:

| user-序号 | item-序号 | rating(也就是星级,打分) |
|         0 |         1 |      5 |
|         0 |       100 |      4 |
|         1 |         3 |      5 |
|       ... |       ... | ...    |

我参考了Fast Item Ranking那篇论文所引用的之前的工作对数据集的处理,将数据集的处理设定为如下步骤:

1. 信息整合. 假设有X个user, Y个item. 那么对该数据集的信息进行读取其实就是构造一个X*Y维的矩阵M. 对于矩阵M, 如果user x与item y出现在了数据集中(也就是上面的表格里),那么M[x,y]=1(无论在数据集rating的评分是多少),如果没有出现,就记作0. 这样就可以生成一个0-1的关系矩阵M.

2. 训练,生成嵌入式向量. 这一步的想法是通过前面的信息,生成每个user,每个item的embedding. pytorch有一个Embedding函数,可以将一个输入的索引(序号,也可以理解为one-hot)转化成一个d维的embedding. 之后,将user与item的embedding输入到匹配函数里(经典的一些相似度,或者MLP),就可以输出一个结果. 对于这个结果, 损失函数的设计应遵循: 如果输入的user与item在矩阵M中对应的数值为1,则希望结果越大越好.否则,则希望越小越好. 通过这个函数,反向训练MLP和embedding的生成.

当我对这个流程了解了之后,我的思索是:为什么一个user对它没有进行评分的item有如此高的matching score(或者说:如此小的距离). 

我觉得解决这个问题肯定要从损失函数入手. 也就是添加大量的无关无关样本结果是0的标签.目前的工作就在这里进行.

