* 樊子恩学长 多动作的对话系统设计
基于RNN做的。

这个算法：
state -> action（1个）

产生过程：
1. 产生动作（从request、inform、thanks等中找到一个）
2. 将动作和关键词放在一起，进行自然语言生成

目前做法：
 RL based。
one hot -> embedding

改进思路：
1） 较长的对话记忆
2） 较短的对话轮数内完成任务

* 张宇超学长  ICDE2019 时序大数据
时间序列匹配（包括精确匹配和近似最近邻搜索）

** iSAX
[[file:./images/20200426195515.png][Capture-20200426195515.png]]
表示的位数可能会发生变化。

添加转置。（Q：转置的意义在哪里呢？）
意义是从字符级到word级

改进：可以加入劝退机制

DTW：dyanamic time walking 特殊的指标



* 雷润泽 无监督近似搜索 2020.01
Flyhash：
从低维度映射到高维度（高维度，但是只有很小的神经元被激活）
[[file:./images/20200426200835.png][Capture-20200426200835.png]]
与LSH的sketch不同，它做了更高维度的投影，然后把大多数给丢掉？

m的设定正如同k的选取，是一个超参。

思路：
1. hash layer W 是训练得到的。
[[file:./images/20200426201416.png][Capture-20200426201416.png]]
Hebbian Learning
采用了一个？损失函数
在一些分布下可以获得全局最优。

启发：
特殊的无监督目标函数。

由于m的维度比较高，W是训练得到的，所以神经元能够跟进于数据点的分布。


